---
title: "Practical session: Sampling from the posterior distribution using MCMC"
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(cache=TRUE, fig.path='figure/mcmc/', cache.path='cache/mcmc/' , fig.cap='', fig.align="center")
```

```{r load, include=FALSE, cache=FALSE}
library(fitR)
data(SIR)
data(SIR_reporting)
```

# Objectives

The aim of this session is to learn how to sample from a posterior distribution using MCMC with the Metropolis-Hastings algorithm. More specifically, in this session you will

1. code your first MCMC algorithm to sample from an univariate distribution
2. use it to sample from the posterior distribution of $R_0$ from the previous session. 

# An MCMC sampler

Below, you will see the code for a function called `mcmcMH` to sample from a univariate distribution, i.e. one that has a single parameter, using the Metropolis-Hastings algorithm. The proposal distribution $q(\theta'|\theta)$ is a standard Gaussian. It takes four arguments: 

1. a function that can *evaluate* the target distribution at any value of its parameter
2. an initial value for the parameter
3. the standard deviation of the (Gaussian) *proposal distribution* (i.e., the average step size of the sampler)
4. the number of iterations for which to run the sampler. 

The `mcmcMH` function evaluates the target distribution at the given initial parameter value, and then applies the Metropolis-Hastings algorithm for the specified number of iterations. Read the function code and comments carefully and make sure that you understand what the function does. If you there are any functions that you don't know (e.g., `rnorm`), you can find out about it using `?` (e.g., `?rnorm`)

```{r mcmc, eval = FALSE, tidy = FALSE}
# This is a function that takes four parameters:
# - target: the target distribution, a function that takes one
#   argument (a number) and returns the (logged) value of a
#   distribution
# - init.theta: the initial value of theta, a number
# - proposal.sd: the standard deviation of (Gaussian) proposal
#   distribution
# - n.iterations: the number of iterations
# The function returns a vector of samples of theta from the target
# distribution
mcmcMH <- function(target, init.theta, proposal.sd, n.iterations) {

    # evaluate the function "target" at "init.theta", and assign to
    # a variable called target.theta.current.
    target.theta.current <- target(init.theta)

    # initialise variables to store the current value of theta, the
    # vector of samples, and the number of accepted runs
    theta.current <- init.theta
    samples <- theta.current
    accepted <- 0

    # run MCMC for n.iteration interations
    for (i.iteration in seq_len(n.iterations)) {

        # draw a new theta from the (Gaussian) proposal distribution
        # and assign to a variable called theta.proposed.  
        # See "?rnorm for more information
        # Note that this step is vectorized for any arbitratry theta 
        # which will be useful when we will sample from a multivariate
        # target distribution
        theta.proposed <- rnorm(n = length(theta.current),
                                mean = theta.current,
                                sd = proposal.sd)

        # Note that 'rnorm' returns an unnamed vector, but the functions of
        # 'fitmodel' need a named parameter vector. We therefore set
        # the names of theta.proposed to be the same as the names of
        # theta.current
        names(theta.proposed) <- names(theta.current)

        # evaluate the function target at the proposed theta and
        # assign to a variable called target.theta.proposed
        target.theta.proposed <- target(theta.proposed)

        # compute Metropolis-Hastings ratio (acceptance probability). Since
        # the multivariate Gaussian is symmetric, we don't need to consider
        # the proposal distribution here
        log.acceptance <- target.theta.proposed - target.theta.current

        # draw random number number between 0 and 1 using "runif" and assign to
        # a variable called r.
        r <- runif(1)

        # test acceptance by comparing the random number to the
        # Metropolis-Hastings ratio (acceptance probability) (using
        # "exp" because we calculated the logarithm of the
        # Metropolis-Hastings ratio before)
        if (r < exp(log.acceptance)) {

            # if accepted:
            # change the current value of theta to the proposed theta
            theta.current <- theta.proposed

            # updated the current value of the target
            target.theta.current <- target.theta.proposed

            # update number of accepted proposals
            accepted <- accepted + 1
        }

        # add the current theta to the vector of samples
        # Note that we use `rbind` in order to deal with multivariate 
        # target. So if `theta` is a vector then `samples` is a matrix.
        samples <- rbind(samples, theta.current, deparse.level=0)

        # print current state of chain and acceptance rate
        # use paste() to deal with the case where `theta` is a vector
        message("iteration: ", i.iteration, ", chain:", paste(theta.current, collapse=" "),
                ", acceptance rate:", accepted / i.iteration)

    }

    # return the trace of the chain (i.e., the vector of samples)
    return(samples)
}
```

# Sampling from a posterior distribution

We can now use the Metropolis-Hastings sampler to sample from the posterior distribution of the previous practical. You should have a `my_dLogPosterior` function that evaluates the posterior distribution at a given value of the parameters and initial state, for a given model and with respect to a given data set (if you don't have this function, you can use the one from our [solution](posterior_example_solution.html)). Again, we need to slightly adapt this to be able to explore it with our Metropolis-Hastings sampler.

Remember that `mcmcMH` samples from a distribution that has a single parameter. Our simplest SIR model, however has two parameters: the basic reproduction number $R_0$ and the duration of infection $D_\mathrm{inf}$. So for now, we are going to keep the duration of infection fixed at 2 weeks and just explore the posterior distribution of $R_0$. 

Lastly, `my_dLogPosterior` takes four parameters, and to use it with the `mcmcMH` function we have to turn it into a function that just takes one parameter, here $R_0$. Again, we use a wrapper function for this, which returns the posterior density for a given value of $R_0$ for the `SIR` model with respect to the `epi1` data set, and for fixed `init.state` ($X_0$).


<!-- We can do this by setting `sd.proposal` to a vector of standard deviations, where the second element (if `D_inf` is the second parameter in `theta`) is 0. -->


```{r source_our_logpost, echo=FALSE}
source("our_posterior.r")
```

```{r write_logpost}
my_dLogPosterior_R0_epi1 <- function(R0) {

  return(my_dLogPosterior(fitmodel = SIR,
                          theta = c(R0 = R0, D_inf = 2),
                          init.state = c(S = 999, I = 1, R = 0),
                          data = epi1))
}
```

We can test that this function returns the value of the posterior for a given value of $R_0$.

```{r eval_logpost}
my_dLogPosterior_R0_epi1(R0 = 3)
```

You should get the same number unless you changed the `SIR$dPointObs` function.

Try to generate samples from `my_dLogPosterior_R0_epi1` using `mcmcMH`. Can you work out the command to do this?__ If you have any problems with this, have a look at our [solution](generate_samples.html).

Once you have generated the samples from the posterior distribution, you can calculate summary statistics such as:

* sample mean of $R_0$ using `mean(trace)`, 
* sample median using `median(trace)`
* 95% credible intervals using `quantile(trace, probs=c(0.025, 0.975))`.

Try to re-run your MCMC with different values for `init.theta` (the starting values for $R_0$), for `proposal.sd` (the standard deviation of the Gaussian proposal distribution $q(\theta'|\theta)$), and for `iter` (the number of iterations). Look at plots generated using `plot` and `hist` (see above), summary statistics and the acceptance rate.

Check how the answers to the following questions depend on parameters:

1. What is the [maximum a posteriori probability estimate](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation) (MAP) of $R_0$? Does this match your estimate from the previous session?
2. What determines the acceptance rate?
3. How many iterations do you need to get a good estimate for $R_0$?

<div>
Top: [Index](index.html) Previous: [Using the fitR package](using_fitR.html)
</div>
